{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7faQdWV42JCt",
        "outputId": "421a6999-f0f7-43d1-91a5-8568f1d182ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "# these pakages are need to run ingoogle colab\n",
        "\n",
        "\n",
        "#!pip install pytesseract\n",
        "#!sudo apt-get install tesseract-ocr\n",
        "#!pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the image\n",
        "image = cv2.imread('bill.jpg')\n",
        "\n",
        "\n",
        "\n",
        "# Determine the dimensions of the image\n",
        "height, width, channels = image.shape\n",
        "print(image.shape)\n",
        "\n",
        "# Divide the image into segmentation\n",
        "top_half = image[:380, :, :]\n",
        "middle_half = image[320:480,:,:]\n",
        "middle_two = image[320:980,:750,:]\n",
        "bottom_half = image[820:, :, :]\n",
        "\n",
        "# segmentation of image for preprocessing\n",
        "cv2.imwrite('top_half.jpg', top_half)\n",
        "\n",
        "cv2.imwrite('middle_half.jpg', middle_half)\n",
        "\n",
        "cv2.imwrite('middle_half2.jpg', middle_two)\n",
        "\n",
        "cv2.imwrite('bottom_half.jpg', bottom_half)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCfGb7Rg2TeJ",
        "outputId": "790cc739-6910-4929-8eb4-9c4fb9e3b3e4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 768, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bill_text1 = pytesseract.image_to_string(top_half)\n",
        "bill_text2 = pytesseract.image_to_string(middle_half)\n",
        "bill_text3 = pytesseract.image_to_string(middle_two)\n",
        "bill_text4 = pytesseract.image_to_string(bottom_half)\n",
        "print(bill_text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ETSqM_PTZp",
        "outputId": "6931e5ae-0801-4e4c-c981-4885eb7dfbbd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARCO POLO ORTIGAS MANILA\n",
            "Owned by\n",
            "FRONTIER ORTIGAS\n",
            "\n",
            "HOTEL and RESORT CORP.\n",
            "Meralco Ave. & Sapphire Rd.\n",
            "\n",
            "Ortigas Ctr., Pasig City\n",
            "\n",
            "1600 Philippines\n",
            "\n",
            "VAT REG TIN: 008-611-772-000\n",
            "\n",
            " \n",
            "\n",
            "LUNG HIN\n",
            "Table: Ri NPE »7WNHEO—HH\n",
            "\n",
            "  \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "#generate the texts from the images\n",
        "bill_text1 = pytesseract.image_to_string(image)\n",
        "bill_text2 = pytesseract.image_to_string(middle_half)\n",
        "bill_text3 = pytesseract.image_to_string(middle_two)\n",
        "bill_text4 = pytesseract.image_to_string(bottom_half)\n",
        "\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "# The text from the image\n",
        "\"\"\"\n",
        "MARCO POLO ORTIGAS MANILA\n",
        "Owned by\n",
        "HOTEL and RESORT CORP.\n",
        "Meralco Ave. & Sapphire Rd.\n",
        "Ortigas Ctr., Pasig City\n",
        "1600 Philippines\n",
        "VAT REG TIN: 008-611-772-000\n",
        "\"\"\"\n",
        "bill_text = bill_text1\n",
        "# Define regular expressions to extract relevant information\n",
        "shop_name_pattern = r\"MARCO POLO ORTIGAS MANILA\"\n",
        "owner_name_pattern = r\"Owned by\\n([^\\n]+)\"\n",
        "address_pattern = r\"Owned by([\\s\\S]+?)VAT REG TIN\"\n",
        "reg_no_pattern = r\"VAT REG TIN: (\\d{3}-\\d{3}-\\d{3}-\\d{3})\"\n",
        "\n",
        "# Initialize a dictionary to store extracted information\n",
        "data = {\n",
        "    \"Shop Name\": None,\n",
        "    \"Owner Name\": None,\n",
        "    \"Address\": {\n",
        "        \"Organization\": None,\n",
        "        \"Street\": None,\n",
        "        \"City\": None,\n",
        "        \"Postal Code\": None,\n",
        "        \"Country\": None\n",
        "    },\n",
        "    \"Registration Number\": None\n",
        "}\n",
        "\n",
        "# Extract information using regular expressions\n",
        "shop_name_match = re.search(shop_name_pattern, bill_text)\n",
        "if shop_name_match:\n",
        "    data[\"Shop Name\"] = shop_name_match.group(0)\n",
        "\n",
        "owner_name_match = re.search(owner_name_pattern, bill_text)\n",
        "if owner_name_match:\n",
        "    data[\"Owner Name\"] = owner_name_match.group(1).strip()\n",
        "\n",
        "address_match = re.search(address_pattern, bill_text)\n",
        "if address_match:\n",
        "    address_text = address_match.group(1).strip()\n",
        "    address_parts = address_text.split('\\n')\n",
        "\n",
        "    if len(address_parts) >= 4:\n",
        "        data[\"Address\"][\"Organization\"] = address_parts[0].strip()\n",
        "        data[\"Address\"][\"Street\"] = address_parts[1].strip()\n",
        "        data[\"Address\"][\"City\"] = address_parts[2].strip()\n",
        "\n",
        "        postal_code_country = address_parts[-1].split(' ')\n",
        "        if len(postal_code_country) == 2:\n",
        "            data[\"Address\"][\"Postal Code\"] = postal_code_country[0].strip()\n",
        "            data[\"Address\"][\"Country\"] = postal_code_country[1].strip()\n",
        "\n",
        "reg_no_match = re.search(reg_no_pattern, bill_text)\n",
        "if reg_no_match:\n",
        "    data[\"Registration Number\"] = reg_no_match.group(1)\n",
        "\n",
        "# Convert the dictionary to JSON format\n",
        "output_json1 = json.dumps(data, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "# The text from the image\n",
        "bill_text = bill_text2\n",
        "\"\"\"\n",
        "LUNG HIN\n",
        "Table: Bi OR# :333099-00\n",
        "Date +: 08 Feb,i5 Time +: 12:49\n",
        "Staff : ALEMIR Cover : 3\n",
        "\n",
        "Kio o0©0 OJ QSMINE 179.57\n",
        "\"\"\"\n",
        "\n",
        "# Define regular expressions to extract date, time, staff, cover, and table details\n",
        "#date_pattern = r\"Date +: (\\d{2} \\w+,\\w+\\d{2})\"\n",
        "#time_pattern = r\"Time +: (\\d{2}:\\d{2})\"\n",
        "date_time_pattern = r\"Date \\+: ([\\d\\s\\w,:]+) Time \\+: ([\\d:]+)\"\n",
        "\n",
        "staff_pattern = r\"Staff : (\\w+) Cover : (\\d+)\"\n",
        "table_pattern = r\"Table: (\\w+) OR# :(\\d+)\"\n",
        "\n",
        "# Initialize variables to store extracted details\n",
        "date = None\n",
        "time = None\n",
        "staff_name = None\n",
        "cover = None\n",
        "table_name = None\n",
        "table_number = None\n",
        "\n",
        "attributes = {\n",
        "    \"Date\": None,\n",
        "    \"Time\": None,\n",
        "\n",
        "}\n",
        "\n",
        "# Extract date, time, staff, cover, and table details using regular expressions\n",
        "\n",
        "date_time_match = re.search(date_time_pattern, bill_text)\n",
        "if date_time_match:\n",
        "    attributes[\"Date\"] = date_time_match.group(1)\n",
        "    attributes[\"Time\"] = date_time_match.group(2)\n",
        "\n",
        "\n",
        "\n",
        "staff_match = re.search(staff_pattern, bill_text)\n",
        "if staff_match:\n",
        "    staff_name = staff_match.group(1)\n",
        "    cover = int(staff_match.group(2))\n",
        "\n",
        "table_match = re.search(table_pattern, bill_text)\n",
        "if table_match:\n",
        "    table_name = table_match.group(1)\n",
        "    table_number = table_match.group(2)\n",
        "\n",
        "# Store the details in a dictionary\n",
        "details = {\n",
        "    \"Table\": {\n",
        "        \"Name\": table_name,\n",
        "        \"Number\": table_number\n",
        "    },\n",
        "\n",
        "    \"Staff\": {\n",
        "        \"Name\": staff_name,\n",
        "        \"Cover\": cover\n",
        "    }\n",
        "}\n",
        "\n",
        "# Convert the dictionary to JSON format\n",
        "output_json2 = json.dumps(details, indent=4)\n",
        "\n",
        "output_json3 = json.dumps(attributes, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "# The text from the image\n",
        "bill_text = \"\"\"\n",
        "VaTable 1770.93\n",
        "10% S.C. 260.72\n",
        "12% VAT 212.51\n",
        "LTax Fd/By 49.59\n",
        "\n",
        "Total: 2293.75\n",
        "\"\"\"\n",
        "\n",
        "# Define regular expressions to extract relevant information\n",
        "vatable_pattern = r\"VaTable (\\d+\\.\\d+)\"\n",
        "service_charge_pattern = r\"10% S.C. (\\d+\\.\\d+)\"\n",
        "vat_pattern = r\"12% VAT (\\d+\\.\\d+)\"\n",
        "ltax_pattern = r\"LTax Fd/By (\\d+\\.\\d+)\"\n",
        "total_pattern = r\"Total: (\\d+\\.\\d+)\"\n",
        "\n",
        "# Initialize a dictionary to store extracted information\n",
        "data = {\n",
        "    \"VATable\": None,\n",
        "    \"Service Charge\": None,\n",
        "    \"VAT\": None,\n",
        "    \"LTax\": None,\n",
        "    \"Total\": None\n",
        "}\n",
        "\n",
        "# Extract information using regular expressions\n",
        "vatable_match = re.search(vatable_pattern, bill_text)\n",
        "if vatable_match:\n",
        "    data[\"VATable\"] = float(vatable_match.group(1))\n",
        "\n",
        "service_charge_match = re.search(service_charge_pattern, bill_text)\n",
        "if service_charge_match:\n",
        "    data[\"Service Charge\"] = float(service_charge_match.group(1))\n",
        "\n",
        "vat_match = re.search(vat_pattern, bill_text)\n",
        "if vat_match:\n",
        "    data[\"VAT\"] = float(vat_match.group(1))\n",
        "\n",
        "ltax_match = re.search(ltax_pattern, bill_text)\n",
        "if ltax_match:\n",
        "    data[\"LTax\"] = float(ltax_match.group(1))\n",
        "\n",
        "total_match = re.search(total_pattern, bill_text)\n",
        "if total_match:\n",
        "    data[\"Total\"] = float(total_match.group(1))\n",
        "\n",
        "# Convert the dictionary to JSON format\n",
        "output_json5 = json.dumps(data, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "# The text from the image\n",
        "bill_text = \"\"\"\n",
        "LUNG HIN\n",
        "Table: Bi OR# :333099-00\n",
        "Date +: 08 Feb,iS Time +: 12:49\n",
        "Staff +: ALEMIR Cover : 3\n",
        "\n",
        "¥1 0 JASMINE 178.57\n",
        "41 ST.CHX FEET x0 160.71\n",
        "¥100 ST.PORK SIOMAT 196.43\n",
        "x10 ST.G RICE ABALONE 196.43\n",
        "\n",
        "X10 ST.SPINACH DUMPLING © 196.43\n",
        "a2 ST.SCALLOP DUMPLING 428.58\n",
        "1 BAKED BRQ PORK BUN 196.43\n",
        "x1 PANFRIED ONION CAKE 194.43\n",
        "¥1 FISH SCALLOP SP Px 339.29\n",
        "41) MAR BEEF GARLIC 517.86\n",
        "MPM DP 15% Bey petra\n",
        "\n",
        "MPM Dining Privilege 809.44\n",
        "a\n",
        "\n",
        "Sub-Tote 1770.93\n",
        "\n",
        "VATable 1770.93\n",
        "10% S.C. 260.72\n",
        "12% VAT 212.51\n",
        "LTax 49,59\n",
        "\n",
        "Total: 2299.75\n",
        "\"\"\"\n",
        "\n",
        "# Define regular expressions to extract relevant information\n",
        "\n",
        "item_pattern = r\"(\\d+) (.+?) (\\d+\\.\\d+)\"\n",
        "subtotal_pattern = r\"Sub-Tote (\\d+\\.\\d+)\"\n",
        "mpm_dining_pattern = r\"MPM Dining Privilege ([\\d\\.\\d+]+)\"\n",
        "\n",
        "# Initialize variables to store extracted attributes\n",
        "attributes = {\n",
        "\n",
        "    \"Items\": [],\n",
        "    \"Subtotal\": None,\n",
        "    \"MPM Dining Privilege\": None\n",
        "}\n",
        "\n",
        "# Extract and store attributes\n",
        "\n",
        "item_matches = re.findall(item_pattern, bill_text)\n",
        "for item_match in item_matches:\n",
        "    quantity, item_name, price = item_match\n",
        "    attributes[\"Items\"].append({\n",
        "        #\"Quantity\": int(quantity),\n",
        "        \"Item Name\": item_name,\n",
        "        \"Price\": float(price)\n",
        "    })\n",
        "\n",
        "subtotal_match = re.search(subtotal_pattern, bill_text)\n",
        "if subtotal_match:\n",
        "    attributes[\"Subtotal\"] = float(subtotal_match.group(1))\n",
        "\n",
        "mpm_dining_match = re.search(mpm_dining_pattern, bill_text)\n",
        "if mpm_dining_match:\n",
        "    attributes[\"MPM Dining Privilege\"] = -float(mpm_dining_match.group(1).replace(',', ''))\n",
        "\n",
        "# Convert the attributes to JSON\n",
        "output_json4 = json.dumps(attributes, indent=4)\n",
        "\n",
        "# Print the JSON output\n",
        "print(output_json1)\n",
        "# Print the JSON output\n",
        "print(output_json2)\n",
        "# Print the JSON output\n",
        "print(output_json3)\n",
        "# Print the JSON output\n",
        "print(output_json4)\n",
        "print(output_json5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hTu_e2z213R",
        "outputId": "f318a344-2227-4e3c-ac35-c1f7700acba2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Shop Name\": \"MARCO POLO ORTIGAS MANILA\",\n",
            "    \"Owner Name\": \"FRONTIER ORTIGAS\",\n",
            "    \"Address\": {\n",
            "        \"Organization\": \"FRONTIER ORTIGAS\",\n",
            "        \"Street\": \"HOTEL and RESORT CORP.\",\n",
            "        \"City\": \"Meralco Ave. & Sapphire Rd.\",\n",
            "        \"Postal Code\": \"1400\",\n",
            "        \"Country\": \"Philippines\"\n",
            "    },\n",
            "    \"Registration Number\": \"008-611-772-000\"\n",
            "}\n",
            "{\n",
            "    \"Table\": {\n",
            "        \"Name\": \"Bi\",\n",
            "        \"Number\": \"333099\"\n",
            "    },\n",
            "    \"Staff\": {\n",
            "        \"Name\": \"ALEMIR\",\n",
            "        \"Cover\": 3\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"Date\": \"08 Feb,i5\",\n",
            "    \"Time\": \"12:49\"\n",
            "}\n",
            "{\n",
            "    \"Items\": [\n",
            "        {\n",
            "            \"Item Name\": \"0 JASMINE\",\n",
            "            \"Price\": 178.57\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"ST.CHX FEET x0\",\n",
            "            \"Price\": 160.71\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"ST.PORK SIOMAT\",\n",
            "            \"Price\": 196.43\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"ST.G RICE ABALONE\",\n",
            "            \"Price\": 196.43\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"ST.SPINACH DUMPLING \\u00a9\",\n",
            "            \"Price\": 196.43\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"ST.SCALLOP DUMPLING\",\n",
            "            \"Price\": 428.58\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"BAKED BRQ PORK BUN\",\n",
            "            \"Price\": 196.43\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"PANFRIED ONION CAKE\",\n",
            "            \"Price\": 194.43\n",
            "        },\n",
            "        {\n",
            "            \"Item Name\": \"FISH SCALLOP SP Px\",\n",
            "            \"Price\": 339.29\n",
            "        }\n",
            "    ],\n",
            "    \"Subtotal\": 1770.93,\n",
            "    \"MPM Dining Privilege\": -809.44\n",
            "}\n",
            "{\n",
            "    \"VATable\": 1770.93,\n",
            "    \"Service Charge\": 260.72,\n",
            "    \"VAT\": 212.51,\n",
            "    \"LTax\": 49.59,\n",
            "    \"Total\": 2293.75\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Notes\n",
        " here I tried with  other preprocessing techniques with de noising, border removal, Intensity transformations.      But those give the outputs which  are less perfect compare to this approach\n",
        "\n",
        " I append those codes as well."
      ],
      "metadata": {
        "id": "pJSNBiP2MLZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#approach one\n",
        "import numpy as np\n",
        "\n",
        "def mapp(h):\n",
        "    h = h.reshape((4,2))\n",
        "    hnew = np.zeros((4,2),dtype = np.float32)\n",
        "\n",
        "    add = h.sum(1)\n",
        "    hnew[0] = h[np.argmin(add)]\n",
        "    hnew[2] = h[np.argmax(add)]\n",
        "\n",
        "    diff = np.diff(h,axis = 1)\n",
        "    hnew[1] = h[np.argmin(diff)]\n",
        "    hnew[3] = h[np.argmax(diff)]\n",
        "\n",
        "    return hnew\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "image=cv2.imread(\"top_half.jpg\")   #read in the image\n",
        "image=cv2.resize(image,(700,800)) #resizing because opencv does not work well with bigger images\n",
        "orig=image.copy()\n",
        "\n",
        "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  #RGB To Gray Scale\n",
        "thresh, im_bw = cv2.threshold(gray, 140, 220, cv2.THRESH_BINARY)\n",
        "cv2.imwrite(\"bw_image.jpg\", im_bw)\n",
        "\n",
        "blurred=cv2.GaussianBlur(gray,(3,3),0.2)  #(5,5) is the kernel size and 0 is sigma that determines the amount of blur\n",
        "#cv2.imshow(\"Blur\",blurred)\n",
        "\n",
        "edged=cv2.Canny(blurred,30,60)  #30 MinThreshold and 50 is the MaxThreshold\n",
        "#cv2.imshow(\"Canny\",edged)\n",
        "\n",
        "\n",
        "contours,hierarchy=cv2.findContours(edged,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)  #retrieve the contours as a list, with simple apprximation model\n",
        "contours=sorted(contours,key=cv2.contourArea,reverse=True)\n",
        "\n",
        "#the loop extracts the boundary contours of the page\n",
        "for c in contours:\n",
        "    p=cv2.arcLength(c,True)\n",
        "    approx=cv2.approxPolyDP(c,0.02*p,True)\n",
        "\n",
        "    if len(approx)==4:\n",
        "        target=approx\n",
        "        break\n",
        "approx=mapp(target) #find endpoints of the sheet\n",
        "\n",
        "pts=np.float32([[0,0],[800,0],[800,800],[0,800]])  #map to 800*800 target window\n",
        "\n",
        "op=cv2.getPerspectiveTransform(approx,pts)  #get the top or bird eye view effect\n",
        "dst=cv2.warpPerspective(orig,op,(800,800))\n",
        "\n",
        "plt.imshow(dst)\n",
        "#cv2.imshow(\"Scanned\",dst)\n",
        "# press q or Esc to close\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#approach two\n",
        "\n",
        "#transform = np.arange(255,-1,-1).astype(\"uint8\")\n",
        "#gray = cv2.LUT(gray, transform)\n",
        "#cv2.imshow(\"Title\",gray)\n",
        "def noise_removal(image):\n",
        "    import numpy as np\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    image = cv2.dilate(image, kernel, iterations=1)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    image = cv2.erode(image, kernel, iterations=1)\n",
        "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "    image = cv2.medianBlur(image, 3)\n",
        "    return (image)\n",
        "\n",
        "def remove_borders(image):\n",
        "    contours, heiarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cntsSorted = sorted(contours, key=lambda x:cv2.contourArea(x))\n",
        "    cnt = cntsSorted[-1]\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    crop = image[y:y+h, x:x+w]\n",
        "    return (crop)\n",
        "\n",
        "no_noise = noise_removal(im_bw)\n",
        "cv2.imwrite(\"no_noise.jpg\", no_noise)\n",
        "no_borders = remove_borders(im_bw)\n",
        "cv2.imwrite(\"no_borders.jpg\", no_borders)\n",
        "display('no_borders.jpg')\n",
        "plt.imshow(no_borders)\n",
        "\n"
      ],
      "metadata": {
        "id": "1L20JRjfMpCz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}